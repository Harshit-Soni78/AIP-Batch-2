{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in c:\\python312\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: keras in c:\\python312\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (2.19.0rc0)\n",
      "Requirement already satisfied: nltk in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (3.9.1)\n",
      "Requirement already satisfied: absl-py in c:\\python312\\lib\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: rich in c:\\python312\\lib\\site-packages (from keras) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\python312\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\python312\\lib\\site-packages (from keras) (3.12.1)\n",
      "Requirement already satisfied: optree in c:\\python312\\lib\\site-packages (from keras) (0.13.1)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from keras) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\python312\\lib\\site-packages (from keras) (24.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\python312\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\python312\\lib\\site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\python312\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\python312\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\python312\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\python312\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\python312\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\python312\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\python312\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\python312\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\python312\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.71.0rc2)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: click in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\python312\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\python312\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\python312\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\harsh\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: colorama in c:\\python312\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\python312\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\python312\\lib\\site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\python312\\lib\\site-packages\\vboxapi-1.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy keras tensorflow nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD\n",
    "# import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `nltk` – Used for tokenization and lemmatization.\n",
    "-   `json` – Loads the intent dataset from a JSON file.\n",
    "-   `pickle` – Saves and loads processed data (`words.pkl`, `classes.pkl`).\n",
    "-   `random` – Shuffles training data to improve generalization.\n",
    "-   `numpy` – Handles data processing and numerical operations.\n",
    "-   `WordNetLemmatizer` – Converts words to their base form (e.g., \"running\" → \"run\").\n",
    "-   `keras.models.Sequential` – Defines the neural network architecture.\n",
    "-   `keras.layers.Dense, Dropout` – Adds fully connected layers and dropout for regularization.\n",
    "-   `keras.optimizers.SGD` – Uses Stochastic Gradient Descent for training.\n",
    "-   `os` – Handles file operations.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ensuring NLTK Resources are Available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\harsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Function to check and download NLTK resources if not already available\n",
    "def check_nltk_resources():\n",
    "    try:\n",
    "        nltk.data.find('tokenizers/punkt')\n",
    "    except LookupError:\n",
    "        nltk.download('punkt')\n",
    "    \n",
    "    try:\n",
    "        nltk.data.find('corpora/wordnet')\n",
    "    except LookupError:\n",
    "        nltk.download('wordnet')\n",
    "\n",
    "# Call the function to ensure NLTK resources are available\n",
    "check_nltk_resources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   This function ensures that `punkt` (for tokenization) and `wordnet` (for lemmatization) are downloaded.\n",
    "-   If they are missing, it downloads them.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Load and process the data\n",
    "data_file = open('Data/admission_data.json').read()\n",
    "intents = json.loads(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `WordNetLemmatizer()` – Initializes the lemmatizer for text preprocessing.\n",
    "-   `open('Data/admission_data.json').read()` – Opens and reads the JSON dataset.\n",
    "-   `json.loads(data_file)` – Converts the JSON string into a Python dictionary.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preparing Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_words = ['?', '!']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `words` – Stores unique words from all training sentences.\n",
    "-   `classes` – Stores different intent tags.\n",
    "-   `documents` – Stores word patterns mapped to intent tags.\n",
    "-   `ignore_words` – Excludes punctuation marks.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intents': [{'tag': 'greeting', 'patterns': ['Hi', 'Hello', 'Hey', 'Good day'], 'responses': ['Hello! How can I assist you today?', 'Hi there! How can I help you?', 'Hey! What can I do for you?'], 'context': ''}, {'tag': 'goodbye', 'patterns': ['Bye', 'See you later', 'Goodbye', 'Till next time'], 'responses': ['Goodbye! Have a great day.', 'See you later! Take care.', 'Until next time!'], 'context': ''}, {'tag': 'thanks', 'patterns': ['Thanks', 'Thank you', \"That's helpful\", 'Thanks for helping me'], 'responses': [\"You're welcome!\", 'Glad I could assist!', 'Anytime!'], 'context': ''}, {'tag': 'admission_deadline', 'patterns': ['What is the application deadline?', 'When do I need to apply?', 'Deadline for application?'], 'responses': [\"The application deadline is typically in September. Make sure to check the college's official website for the exact date.\"], 'context': ''}, {'tag': 'admission_requirements', 'patterns': ['What are the admission requirements?', 'What do I need to apply?', 'What documents are required for admission?'], 'responses': [\"To apply, you'll typically need transcripts, test scores, essays, and letters of recommendation. However, requirements may vary by college and program.\"], 'context': ''}, {'tag': 'programs_offered', 'patterns': ['What programs does the college offer?', 'What majors are available?', 'List of courses offered?'], 'responses': [\"The college offers a variety of programs including BE, ME, etc. You can find more details on the college's website.\"], 'context': ''}, {'tag': 'financial_aid', 'patterns': ['Are scholarships available?', 'Can I get financial aid?', 'How can I afford college?'], 'responses': ['Yes, the college offers scholarships and financial aid options. Make sure to explore all available opportunities and deadlines.'], 'context': ''}, {'tag': 'campus_life', 'patterns': ['What is campus life like?', 'Tell me about student activities', 'Are there clubs on campus?'], 'responses': [\"Campus life is vibrant with a variety of student activities, clubs, and events. You'll have plenty of opportunities to get involved and make friends.\"], 'context': ''}, {'tag': 'housing', 'patterns': ['Is housing available for freshmen?', 'What are the housing options?', 'Tell me about dormitories', 'Tell me about staying options'], 'responses': ['Housing is available for freshmen, with options including dormitories and on-campus apartments/hostels. Be sure to apply early to secure your preferred housing option.'], 'context': ''}, {'tag': 'support_services', 'patterns': ['What support services are available for students?', 'Is there academic advising?', 'Are there counseling services?'], 'responses': ['The college offers a range of support services including academic advising, counseling, tutoring, and career services to help students succeed.'], 'context': ''}, {'tag': 'internships', 'patterns': ['Are there internship opportunities?', 'Can I do internships during college?', 'Tell me about work-study programs'], 'responses': ['Yes, the college provides internship opportunities and work-study programs to help students gain real-world experience and build their resumes.'], 'context': ''}, {'tag': 'faculty', 'patterns': ['Tell me about the faculty', 'Are the professors helpful?', 'Do professors offer office hours?'], 'responses': ['The faculty at the college are highly qualified and supportive, often offering office hours to assist students with their academic and research endeavors.'], 'context': ''}, {'tag': 'study_abroad', 'patterns': ['Are there study abroad programs?', 'Can I study abroad during college?', 'Tell me about exchange programs'], 'responses': ['Yes, the college offers study abroad programs and exchange opportunities for students to immerse themselves in different cultures and academic environments.'], 'context': ''}, {'tag': 'diversity', 'patterns': ['What is the diversity of the student body?', 'Tell me about diversity on campus', 'Are there international students?'], 'responses': ['The college prides itself on its diverse student body, with students from various backgrounds and cultures enriching the campus community.'], 'context': ''}, {'tag': 'admission_interview', 'patterns': ['Is there an admission interview?', 'What is the interview process like?', 'Tell me about admission interviews'], 'responses': [\"Yes, there may be an admission interview as part of the application process. It's an opportunity for the college to learn more about you and for you to ask any questions you may have.\"], 'context': ''}, {'tag': 'application_tips', 'patterns': ['Do you have any tips for the application process?', 'How can I improve my application?', 'Tell me about application strategies'], 'responses': ['Make sure to start your application early, thoroughly review all requirements, and showcase your strengths and experiences effectively in your essays and personal statements.'], 'context': ''}, {'tag': 'admission_tests', 'patterns': ['What standardized tests are required?', 'Do I need to take the SAT or ACT?', 'Tell me about admission exams'], 'responses': ['The college may require standardized tests such as the SAT or ACT. Check the admissions website for specific requirements and deadlines.'], 'context': ''}, {'tag': 'financial_planning', 'patterns': ['How much does it cost to attend?', 'What is the tuition fee?', 'Tell me about financial planning for college'], 'responses': ['Tuition fees vary by college and program. Be sure to factor in additional costs such as housing, books, and personal expenses when planning for college.'], 'context': ''}, {'tag': 'admission_status', 'patterns': ['How can I check my admission status?', 'When will I hear back from the college?', 'Tell me about admission decisions'], 'responses': [\"You can usually check your admission status online through the college's admissions portal. Admission decisions are typically communicated by mail or email.\"], 'context': ''}, {'tag': 'application_fee', 'patterns': ['Is there an application fee?', 'How much is the application fee?', 'Tell me about application fees'], 'responses': ['Yes, there may be an application fee. The amount varies by college. Check the admissions website for the current fee and payment instructions.'], 'context': ''}, {'tag': 'academic_support', 'patterns': ['Are there tutoring services available?', 'Can I get help with my studies?', 'Tell me about academic support'], 'responses': ['Yes, the college offers tutoring and academic support services to assist students with their studies. You can often find help through the academic resource center or specific departments.'], 'context': ''}, {'tag': 'career_services', 'patterns': ['Are there career services available?', 'Can I get help with job placement?', 'Tell me about career resources'], 'responses': ['The college provides career services to help students explore career options, develop job search strategies, and connect with potential employers. Take advantage of resume workshops, career fairs, and networking events.'], 'context': ''}, {'tag': 'student_activities', 'patterns': ['Are there extracurricular activities?', 'Tell me about student clubs and organizations', 'What activities can I participate in?'], 'responses': [\"Yes, the college offers a wide range of extracurricular activities including clubs, organizations, sports teams, and cultural events. You'll have plenty of opportunities to pursue your interests and make friends.\"], 'context': ''}, {'tag': 'health_services', 'patterns': ['Are there health services available on campus?', 'Can I access medical care?', 'Tell me about health resources'], 'responses': ['Yes, the college provides health services to students including medical care, counseling, and wellness programs. You can usually find support through the student health center or counseling services.'], 'context': ''}, {'tag': 'scholarship_deadline', 'patterns': ['When is the deadline to apply for scholarships?', 'Tell me about scholarship deadlines', 'How can I apply for scholarships?'], 'responses': [\"Scholarship deadlines vary by program and scholarship. Be sure to check the college's financial aid website for the latest information and application instructions.\"], 'context': ''}, {'tag': 'admission_website', 'patterns': [\"What is the college's official website?\", 'Where can I find more information about admissions?', 'Tell me about the admissions website'], 'responses': [\"You can find more information about admissions on the college's official website. Simply visit [website link] for details on programs, requirements, deadlines, and more.\"], 'context': ''}, {'tag': 'application_process', 'patterns': ['How do I apply?', 'Tell me about the application process', 'What steps do I need to take to apply?'], 'responses': [\"To apply, you'll typically need to complete an online application, submit required documents, and pay any application fees. Check the admissions website for specific instructions and deadlines.\"], 'context': ''}, {'tag': 'financial_aid_application', 'patterns': ['How do I apply for financial aid?', 'Tell me about the financial aid application process', 'What forms do I need to submit for financial aid?'], 'responses': [\"To apply for financial aid, you'll typically need to complete the Free Application for Federal Student Aid (FAFSA) or the college's financial aid application, and submit any required documents such as tax returns or income statements. Be sure to meet all deadlines for consideration.\"], 'context': ''}, {'tag': 'online_resources', 'patterns': ['Are there online resources available for applicants?', 'Tell me about online application resources', 'Where can I find help online?'], 'responses': ['Yes, the college provides online resources for applicants including application guides, FAQs, and contact information for admissions staff. Check the admissions website for assistance with your application.'], 'context': ''}]}\n"
     ]
    }
   ],
   "source": [
    "print(intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        # Tokenize each word in the sentence\n",
    "        w = nltk.word_tokenize(pattern)  # Tokenize each sentence\n",
    "        # Add to documents\n",
    "        words.extend(w)  # Add words to list\n",
    "        \n",
    "        documents.append((w, intent['tag']))  # Store word-intent pair\n",
    "        # Add to classes if not already present\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi', 'Hello', 'Hey', 'Good', 'day', 'Bye', 'See', 'you', 'later', 'Goodbye', 'Till', 'next', 'time', 'Thanks', 'Thank', 'you', 'That', \"'s\", 'helpful', 'Thanks', 'for', 'helping', 'me', 'What', 'is', 'the', 'application', 'deadline', '?', 'When', 'do', 'I', 'need', 'to', 'apply', '?', 'Deadline', 'for', 'application', '?', 'What', 'are', 'the', 'admission', 'requirements', '?', 'What', 'do', 'I', 'need', 'to', 'apply', '?', 'What', 'documents', 'are', 'required', 'for', 'admission', '?', 'What', 'programs', 'does', 'the', 'college', 'offer', '?', 'What', 'majors', 'are', 'available', '?', 'List', 'of', 'courses', 'offered', '?', 'Are', 'scholarships', 'available', '?', 'Can', 'I', 'get', 'financial', 'aid', '?', 'How', 'can', 'I', 'afford', 'college', '?', 'What', 'is', 'campus', 'life', 'like', '?', 'Tell', 'me', 'about', 'student', 'activities', 'Are', 'there', 'clubs', 'on', 'campus', '?', 'Is', 'housing', 'available', 'for', 'freshmen', '?', 'What', 'are', 'the', 'housing', 'options', '?', 'Tell', 'me', 'about', 'dormitories', 'Tell', 'me', 'about', 'staying', 'options', 'What', 'support', 'services', 'are', 'available', 'for', 'students', '?', 'Is', 'there', 'academic', 'advising', '?', 'Are', 'there', 'counseling', 'services', '?', 'Are', 'there', 'internship', 'opportunities', '?', 'Can', 'I', 'do', 'internships', 'during', 'college', '?', 'Tell', 'me', 'about', 'work-study', 'programs', 'Tell', 'me', 'about', 'the', 'faculty', 'Are', 'the', 'professors', 'helpful', '?', 'Do', 'professors', 'offer', 'office', 'hours', '?', 'Are', 'there', 'study', 'abroad', 'programs', '?', 'Can', 'I', 'study', 'abroad', 'during', 'college', '?', 'Tell', 'me', 'about', 'exchange', 'programs', 'What', 'is', 'the', 'diversity', 'of', 'the', 'student', 'body', '?', 'Tell', 'me', 'about', 'diversity', 'on', 'campus', 'Are', 'there', 'international', 'students', '?', 'Is', 'there', 'an', 'admission', 'interview', '?', 'What', 'is', 'the', 'interview', 'process', 'like', '?', 'Tell', 'me', 'about', 'admission', 'interviews', 'Do', 'you', 'have', 'any', 'tips', 'for', 'the', 'application', 'process', '?', 'How', 'can', 'I', 'improve', 'my', 'application', '?', 'Tell', 'me', 'about', 'application', 'strategies', 'What', 'standardized', 'tests', 'are', 'required', '?', 'Do', 'I', 'need', 'to', 'take', 'the', 'SAT', 'or', 'ACT', '?', 'Tell', 'me', 'about', 'admission', 'exams', 'How', 'much', 'does', 'it', 'cost', 'to', 'attend', '?', 'What', 'is', 'the', 'tuition', 'fee', '?', 'Tell', 'me', 'about', 'financial', 'planning', 'for', 'college', 'How', 'can', 'I', 'check', 'my', 'admission', 'status', '?', 'When', 'will', 'I', 'hear', 'back', 'from', 'the', 'college', '?', 'Tell', 'me', 'about', 'admission', 'decisions', 'Is', 'there', 'an', 'application', 'fee', '?', 'How', 'much', 'is', 'the', 'application', 'fee', '?', 'Tell', 'me', 'about', 'application', 'fees', 'Are', 'there', 'tutoring', 'services', 'available', '?', 'Can', 'I', 'get', 'help', 'with', 'my', 'studies', '?', 'Tell', 'me', 'about', 'academic', 'support', 'Are', 'there', 'career', 'services', 'available', '?', 'Can', 'I', 'get', 'help', 'with', 'job', 'placement', '?', 'Tell', 'me', 'about', 'career', 'resources', 'Are', 'there', 'extracurricular', 'activities', '?', 'Tell', 'me', 'about', 'student', 'clubs', 'and', 'organizations', 'What', 'activities', 'can', 'I', 'participate', 'in', '?', 'Are', 'there', 'health', 'services', 'available', 'on', 'campus', '?', 'Can', 'I', 'access', 'medical', 'care', '?', 'Tell', 'me', 'about', 'health', 'resources', 'When', 'is', 'the', 'deadline', 'to', 'apply', 'for', 'scholarships', '?', 'Tell', 'me', 'about', 'scholarship', 'deadlines', 'How', 'can', 'I', 'apply', 'for', 'scholarships', '?', 'What', 'is', 'the', 'college', \"'s\", 'official', 'website', '?', 'Where', 'can', 'I', 'find', 'more', 'information', 'about', 'admissions', '?', 'Tell', 'me', 'about', 'the', 'admissions', 'website', 'How', 'do', 'I', 'apply', '?', 'Tell', 'me', 'about', 'the', 'application', 'process', 'What', 'steps', 'do', 'I', 'need', 'to', 'take', 'to', 'apply', '?', 'How', 'do', 'I', 'apply', 'for', 'financial', 'aid', '?', 'Tell', 'me', 'about', 'the', 'financial', 'aid', 'application', 'process', 'What', 'forms', 'do', 'I', 'need', 'to', 'submit', 'for', 'financial', 'aid', '?', 'Are', 'there', 'online', 'resources', 'available', 'for', 'applicants', '?', 'Tell', 'me', 'about', 'online', 'application', 'resources', 'Where', 'can', 'I', 'find', 'help', 'online', '?']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91 documents\n",
      "29 classes ['greeting', 'goodbye', 'thanks', 'admission_deadline', 'admission_requirements', 'programs_offered', 'financial_aid', 'campus_life', 'housing', 'support_services', 'internships', 'faculty', 'study_abroad', 'diversity', 'admission_interview', 'application_tips', 'admission_tests', 'financial_planning', 'admission_status', 'application_fee', 'academic_support', 'career_services', 'student_activities', 'health_services', 'scholarship_deadline', 'admission_website', 'application_process', 'financial_aid_application', 'online_resources']\n",
      "531 words ['Hi', 'Hello', 'Hey', 'Good', 'day', 'Bye', 'See', 'you', 'later', 'Goodbye', 'Till', 'next', 'time', 'Thanks', 'Thank', 'you', 'That', \"'s\", 'helpful', 'Thanks', 'for', 'helping', 'me', 'What', 'is', 'the', 'application', 'deadline', '?', 'When', 'do', 'I', 'need', 'to', 'apply', '?', 'Deadline', 'for', 'application', '?', 'What', 'are', 'the', 'admission', 'requirements', '?', 'What', 'do', 'I', 'need', 'to', 'apply', '?', 'What', 'documents', 'are', 'required', 'for', 'admission', '?', 'What', 'programs', 'does', 'the', 'college', 'offer', '?', 'What', 'majors', 'are', 'available', '?', 'List', 'of', 'courses', 'offered', '?', 'Are', 'scholarships', 'available', '?', 'Can', 'I', 'get', 'financial', 'aid', '?', 'How', 'can', 'I', 'afford', 'college', '?', 'What', 'is', 'campus', 'life', 'like', '?', 'Tell', 'me', 'about', 'student', 'activities', 'Are', 'there', 'clubs', 'on', 'campus', '?', 'Is', 'housing', 'available', 'for', 'freshmen', '?', 'What', 'are', 'the', 'housing', 'options', '?', 'Tell', 'me', 'about', 'dormitories', 'Tell', 'me', 'about', 'staying', 'options', 'What', 'support', 'services', 'are', 'available', 'for', 'students', '?', 'Is', 'there', 'academic', 'advising', '?', 'Are', 'there', 'counseling', 'services', '?', 'Are', 'there', 'internship', 'opportunities', '?', 'Can', 'I', 'do', 'internships', 'during', 'college', '?', 'Tell', 'me', 'about', 'work-study', 'programs', 'Tell', 'me', 'about', 'the', 'faculty', 'Are', 'the', 'professors', 'helpful', '?', 'Do', 'professors', 'offer', 'office', 'hours', '?', 'Are', 'there', 'study', 'abroad', 'programs', '?', 'Can', 'I', 'study', 'abroad', 'during', 'college', '?', 'Tell', 'me', 'about', 'exchange', 'programs', 'What', 'is', 'the', 'diversity', 'of', 'the', 'student', 'body', '?', 'Tell', 'me', 'about', 'diversity', 'on', 'campus', 'Are', 'there', 'international', 'students', '?', 'Is', 'there', 'an', 'admission', 'interview', '?', 'What', 'is', 'the', 'interview', 'process', 'like', '?', 'Tell', 'me', 'about', 'admission', 'interviews', 'Do', 'you', 'have', 'any', 'tips', 'for', 'the', 'application', 'process', '?', 'How', 'can', 'I', 'improve', 'my', 'application', '?', 'Tell', 'me', 'about', 'application', 'strategies', 'What', 'standardized', 'tests', 'are', 'required', '?', 'Do', 'I', 'need', 'to', 'take', 'the', 'SAT', 'or', 'ACT', '?', 'Tell', 'me', 'about', 'admission', 'exams', 'How', 'much', 'does', 'it', 'cost', 'to', 'attend', '?', 'What', 'is', 'the', 'tuition', 'fee', '?', 'Tell', 'me', 'about', 'financial', 'planning', 'for', 'college', 'How', 'can', 'I', 'check', 'my', 'admission', 'status', '?', 'When', 'will', 'I', 'hear', 'back', 'from', 'the', 'college', '?', 'Tell', 'me', 'about', 'admission', 'decisions', 'Is', 'there', 'an', 'application', 'fee', '?', 'How', 'much', 'is', 'the', 'application', 'fee', '?', 'Tell', 'me', 'about', 'application', 'fees', 'Are', 'there', 'tutoring', 'services', 'available', '?', 'Can', 'I', 'get', 'help', 'with', 'my', 'studies', '?', 'Tell', 'me', 'about', 'academic', 'support', 'Are', 'there', 'career', 'services', 'available', '?', 'Can', 'I', 'get', 'help', 'with', 'job', 'placement', '?', 'Tell', 'me', 'about', 'career', 'resources', 'Are', 'there', 'extracurricular', 'activities', '?', 'Tell', 'me', 'about', 'student', 'clubs', 'and', 'organizations', 'What', 'activities', 'can', 'I', 'participate', 'in', '?', 'Are', 'there', 'health', 'services', 'available', 'on', 'campus', '?', 'Can', 'I', 'access', 'medical', 'care', '?', 'Tell', 'me', 'about', 'health', 'resources', 'When', 'is', 'the', 'deadline', 'to', 'apply', 'for', 'scholarships', '?', 'Tell', 'me', 'about', 'scholarship', 'deadlines', 'How', 'can', 'I', 'apply', 'for', 'scholarships', '?', 'What', 'is', 'the', 'college', \"'s\", 'official', 'website', '?', 'Where', 'can', 'I', 'find', 'more', 'information', 'about', 'admissions', '?', 'Tell', 'me', 'about', 'the', 'admissions', 'website', 'How', 'do', 'I', 'apply', '?', 'Tell', 'me', 'about', 'the', 'application', 'process', 'What', 'steps', 'do', 'I', 'need', 'to', 'take', 'to', 'apply', '?', 'How', 'do', 'I', 'apply', 'for', 'financial', 'aid', '?', 'Tell', 'me', 'about', 'the', 'financial', 'aid', 'application', 'process', 'What', 'forms', 'do', 'I', 'need', 'to', 'submit', 'for', 'financial', 'aid', '?', 'Are', 'there', 'online', 'resources', 'available', 'for', 'applicants', '?', 'Tell', 'me', 'about', 'online', 'application', 'resources', 'Where', 'can', 'I', 'find', 'help', 'online', '?']\n"
     ]
    }
   ],
   "source": [
    "# Print data information\n",
    "print(len(documents), \"documents\")\n",
    "print(len(classes), \"classes\", classes)\n",
    "print(len(words), \"words\", words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Loops through each intent in the dataset.\n",
    "-   Tokenizes each pattern sentence into words.\n",
    "-   Stores word-tag pairs in `documents` for training.\n",
    "-   Adds new intent tags to `classes`.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize and lower each word and remove duplicates\n",
    "words = sorted(list(set([lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words])))\n",
    "\n",
    "# Sort classes\n",
    "classes = sorted(list(set(classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Converts all words to lowercase and lemmatizes them.\n",
    "-   Removes duplicates and sorts them.\n",
    "-   Sorts `classes` to maintain consistency.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'s\", 'about', 'abroad', 'academic', 'access', 'act', 'activity', 'admission', 'advising', 'afford', 'aid', 'an', 'and', 'any', 'applicant', 'application', 'apply', 'are', 'attend', 'available', 'back', 'body', 'bye', 'campus', 'can', 'care', 'career', 'check', 'club', 'college', 'cost', 'counseling', 'course', 'day', 'deadline', 'decision', 'diversity', 'do', 'document', 'doe', 'dormitory', 'during', 'exam', 'exchange', 'extracurricular', 'faculty', 'fee', 'financial', 'find', 'for', 'form', 'freshman', 'from', 'get', 'good', 'goodbye', 'have', 'health', 'hear', 'hello', 'help', 'helpful', 'helping', 'hey', 'hi', 'hour', 'housing', 'how', 'i', 'improve', 'in', 'information', 'international', 'internship', 'interview', 'is', 'it', 'job', 'later', 'life', 'like', 'list', 'major', 'me', 'medical', 'more', 'much', 'my', 'need', 'next', 'of', 'offer', 'offered', 'office', 'official', 'on', 'online', 'opportunity', 'option', 'or', 'organization', 'participate', 'placement', 'planning', 'process', 'professor', 'program', 'required', 'requirement', 'resource', 'sat', 'scholarship', 'see', 'service', 'standardized', 'status', 'staying', 'step', 'strategy', 'student', 'study', 'submit', 'support', 'take', 'tell', 'test', 'thank', 'thanks', 'that', 'the', 'there', 'till', 'time', 'tip', 'to', 'tuition', 'tutoring', 'website', 'what', 'when', 'where', 'will', 'with', 'work-study', 'you']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['academic_support', 'admission_deadline', 'admission_interview', 'admission_requirements', 'admission_status', 'admission_tests', 'admission_website', 'application_fee', 'application_process', 'application_tips', 'campus_life', 'career_services', 'diversity', 'faculty', 'financial_aid', 'financial_aid_application', 'financial_planning', 'goodbye', 'greeting', 'health_services', 'housing', 'internships', 'online_resources', 'programs_offered', 'scholarship_deadline', 'student_activities', 'study_abroad', 'support_services', 'thanks']\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['Hi'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Bye'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['Till', 'next', 'time'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['Thanks', 'for', 'helping', 'me'], 'thanks'), (['What', 'is', 'the', 'application', 'deadline', '?'], 'admission_deadline'), (['When', 'do', 'I', 'need', 'to', 'apply', '?'], 'admission_deadline'), (['Deadline', 'for', 'application', '?'], 'admission_deadline'), (['What', 'are', 'the', 'admission', 'requirements', '?'], 'admission_requirements'), (['What', 'do', 'I', 'need', 'to', 'apply', '?'], 'admission_requirements'), (['What', 'documents', 'are', 'required', 'for', 'admission', '?'], 'admission_requirements'), (['What', 'programs', 'does', 'the', 'college', 'offer', '?'], 'programs_offered'), (['What', 'majors', 'are', 'available', '?'], 'programs_offered'), (['List', 'of', 'courses', 'offered', '?'], 'programs_offered'), (['Are', 'scholarships', 'available', '?'], 'financial_aid'), (['Can', 'I', 'get', 'financial', 'aid', '?'], 'financial_aid'), (['How', 'can', 'I', 'afford', 'college', '?'], 'financial_aid'), (['What', 'is', 'campus', 'life', 'like', '?'], 'campus_life'), (['Tell', 'me', 'about', 'student', 'activities'], 'campus_life'), (['Are', 'there', 'clubs', 'on', 'campus', '?'], 'campus_life'), (['Is', 'housing', 'available', 'for', 'freshmen', '?'], 'housing'), (['What', 'are', 'the', 'housing', 'options', '?'], 'housing'), (['Tell', 'me', 'about', 'dormitories'], 'housing'), (['Tell', 'me', 'about', 'staying', 'options'], 'housing'), (['What', 'support', 'services', 'are', 'available', 'for', 'students', '?'], 'support_services'), (['Is', 'there', 'academic', 'advising', '?'], 'support_services'), (['Are', 'there', 'counseling', 'services', '?'], 'support_services'), (['Are', 'there', 'internship', 'opportunities', '?'], 'internships'), (['Can', 'I', 'do', 'internships', 'during', 'college', '?'], 'internships'), (['Tell', 'me', 'about', 'work-study', 'programs'], 'internships'), (['Tell', 'me', 'about', 'the', 'faculty'], 'faculty'), (['Are', 'the', 'professors', 'helpful', '?'], 'faculty'), (['Do', 'professors', 'offer', 'office', 'hours', '?'], 'faculty'), (['Are', 'there', 'study', 'abroad', 'programs', '?'], 'study_abroad'), (['Can', 'I', 'study', 'abroad', 'during', 'college', '?'], 'study_abroad'), (['Tell', 'me', 'about', 'exchange', 'programs'], 'study_abroad'), (['What', 'is', 'the', 'diversity', 'of', 'the', 'student', 'body', '?'], 'diversity'), (['Tell', 'me', 'about', 'diversity', 'on', 'campus'], 'diversity'), (['Are', 'there', 'international', 'students', '?'], 'diversity'), (['Is', 'there', 'an', 'admission', 'interview', '?'], 'admission_interview'), (['What', 'is', 'the', 'interview', 'process', 'like', '?'], 'admission_interview'), (['Tell', 'me', 'about', 'admission', 'interviews'], 'admission_interview'), (['Do', 'you', 'have', 'any', 'tips', 'for', 'the', 'application', 'process', '?'], 'application_tips'), (['How', 'can', 'I', 'improve', 'my', 'application', '?'], 'application_tips'), (['Tell', 'me', 'about', 'application', 'strategies'], 'application_tips'), (['What', 'standardized', 'tests', 'are', 'required', '?'], 'admission_tests'), (['Do', 'I', 'need', 'to', 'take', 'the', 'SAT', 'or', 'ACT', '?'], 'admission_tests'), (['Tell', 'me', 'about', 'admission', 'exams'], 'admission_tests'), (['How', 'much', 'does', 'it', 'cost', 'to', 'attend', '?'], 'financial_planning'), (['What', 'is', 'the', 'tuition', 'fee', '?'], 'financial_planning'), (['Tell', 'me', 'about', 'financial', 'planning', 'for', 'college'], 'financial_planning'), (['How', 'can', 'I', 'check', 'my', 'admission', 'status', '?'], 'admission_status'), (['When', 'will', 'I', 'hear', 'back', 'from', 'the', 'college', '?'], 'admission_status'), (['Tell', 'me', 'about', 'admission', 'decisions'], 'admission_status'), (['Is', 'there', 'an', 'application', 'fee', '?'], 'application_fee'), (['How', 'much', 'is', 'the', 'application', 'fee', '?'], 'application_fee'), (['Tell', 'me', 'about', 'application', 'fees'], 'application_fee'), (['Are', 'there', 'tutoring', 'services', 'available', '?'], 'academic_support'), (['Can', 'I', 'get', 'help', 'with', 'my', 'studies', '?'], 'academic_support'), (['Tell', 'me', 'about', 'academic', 'support'], 'academic_support'), (['Are', 'there', 'career', 'services', 'available', '?'], 'career_services'), (['Can', 'I', 'get', 'help', 'with', 'job', 'placement', '?'], 'career_services'), (['Tell', 'me', 'about', 'career', 'resources'], 'career_services'), (['Are', 'there', 'extracurricular', 'activities', '?'], 'student_activities'), (['Tell', 'me', 'about', 'student', 'clubs', 'and', 'organizations'], 'student_activities'), (['What', 'activities', 'can', 'I', 'participate', 'in', '?'], 'student_activities'), (['Are', 'there', 'health', 'services', 'available', 'on', 'campus', '?'], 'health_services'), (['Can', 'I', 'access', 'medical', 'care', '?'], 'health_services'), (['Tell', 'me', 'about', 'health', 'resources'], 'health_services'), (['When', 'is', 'the', 'deadline', 'to', 'apply', 'for', 'scholarships', '?'], 'scholarship_deadline'), (['Tell', 'me', 'about', 'scholarship', 'deadlines'], 'scholarship_deadline'), (['How', 'can', 'I', 'apply', 'for', 'scholarships', '?'], 'scholarship_deadline'), (['What', 'is', 'the', 'college', \"'s\", 'official', 'website', '?'], 'admission_website'), (['Where', 'can', 'I', 'find', 'more', 'information', 'about', 'admissions', '?'], 'admission_website'), (['Tell', 'me', 'about', 'the', 'admissions', 'website'], 'admission_website'), (['How', 'do', 'I', 'apply', '?'], 'application_process'), (['Tell', 'me', 'about', 'the', 'application', 'process'], 'application_process'), (['What', 'steps', 'do', 'I', 'need', 'to', 'take', 'to', 'apply', '?'], 'application_process'), (['How', 'do', 'I', 'apply', 'for', 'financial', 'aid', '?'], 'financial_aid_application'), (['Tell', 'me', 'about', 'the', 'financial', 'aid', 'application', 'process'], 'financial_aid_application'), (['What', 'forms', 'do', 'I', 'need', 'to', 'submit', 'for', 'financial', 'aid', '?'], 'financial_aid_application'), (['Are', 'there', 'online', 'resources', 'available', 'for', 'applicants', '?'], 'online_resources'), (['Tell', 'me', 'about', 'online', 'application', 'resources'], 'online_resources'), (['Where', 'can', 'I', 'find', 'help', 'online', '?'], 'online_resources')]\n"
     ]
    }
   ],
   "source": [
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91 documents\n",
      "29 classes ['academic_support', 'admission_deadline', 'admission_interview', 'admission_requirements', 'admission_status', 'admission_tests', 'admission_website', 'application_fee', 'application_process', 'application_tips', 'campus_life', 'career_services', 'diversity', 'faculty', 'financial_aid', 'financial_aid_application', 'financial_planning', 'goodbye', 'greeting', 'health_services', 'housing', 'internships', 'online_resources', 'programs_offered', 'scholarship_deadline', 'student_activities', 'study_abroad', 'support_services', 'thanks']\n",
      "145 unique lemmatized words [\"'s\", 'about', 'abroad', 'academic', 'access', 'act', 'activity', 'admission', 'advising', 'afford', 'aid', 'an', 'and', 'any', 'applicant', 'application', 'apply', 'are', 'attend', 'available', 'back', 'body', 'bye', 'campus', 'can', 'care', 'career', 'check', 'club', 'college', 'cost', 'counseling', 'course', 'day', 'deadline', 'decision', 'diversity', 'do', 'document', 'doe', 'dormitory', 'during', 'exam', 'exchange', 'extracurricular', 'faculty', 'fee', 'financial', 'find', 'for', 'form', 'freshman', 'from', 'get', 'good', 'goodbye', 'have', 'health', 'hear', 'hello', 'help', 'helpful', 'helping', 'hey', 'hi', 'hour', 'housing', 'how', 'i', 'improve', 'in', 'information', 'international', 'internship', 'interview', 'is', 'it', 'job', 'later', 'life', 'like', 'list', 'major', 'me', 'medical', 'more', 'much', 'my', 'need', 'next', 'of', 'offer', 'offered', 'office', 'official', 'on', 'online', 'opportunity', 'option', 'or', 'organization', 'participate', 'placement', 'planning', 'process', 'professor', 'program', 'required', 'requirement', 'resource', 'sat', 'scholarship', 'see', 'service', 'standardized', 'status', 'staying', 'step', 'strategy', 'student', 'study', 'submit', 'support', 'take', 'tell', 'test', 'thank', 'thanks', 'that', 'the', 'there', 'till', 'time', 'tip', 'to', 'tuition', 'tutoring', 'website', 'what', 'when', 'where', 'will', 'with', 'work-study', 'you']\n"
     ]
    }
   ],
   "source": [
    "# Print data information\n",
    "print(len(documents), \"documents\")\n",
    "print(len(classes), \"classes\", classes)\n",
    "print(len(words), \"unique lemmatized words\", words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Displays summary information about training data.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save words and classes to disk\n",
    "pickle.dump(words, open('Model/words.pkl', 'wb'))\n",
    "pickle.dump(classes, open('Model/classes.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Saves processed `words` and `classes` for later use.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training data\n",
    "training = []\n",
    "output_empty = [0] * len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "print(len(output_empty))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `training` – Stores input-output training data.\n",
    "-   `output_empty` – Initializes a list of zeros to represent class labels.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['Hi'], 'greeting'), (['Hello'], 'greeting'), (['Hey'], 'greeting'), (['Good', 'day'], 'greeting'), (['Bye'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['Till', 'next', 'time'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['Thanks', 'for', 'helping', 'me'], 'thanks'), (['What', 'is', 'the', 'application', 'deadline', '?'], 'admission_deadline'), (['When', 'do', 'I', 'need', 'to', 'apply', '?'], 'admission_deadline'), (['Deadline', 'for', 'application', '?'], 'admission_deadline'), (['What', 'are', 'the', 'admission', 'requirements', '?'], 'admission_requirements'), (['What', 'do', 'I', 'need', 'to', 'apply', '?'], 'admission_requirements'), (['What', 'documents', 'are', 'required', 'for', 'admission', '?'], 'admission_requirements'), (['What', 'programs', 'does', 'the', 'college', 'offer', '?'], 'programs_offered'), (['What', 'majors', 'are', 'available', '?'], 'programs_offered'), (['List', 'of', 'courses', 'offered', '?'], 'programs_offered'), (['Are', 'scholarships', 'available', '?'], 'financial_aid'), (['Can', 'I', 'get', 'financial', 'aid', '?'], 'financial_aid'), (['How', 'can', 'I', 'afford', 'college', '?'], 'financial_aid'), (['What', 'is', 'campus', 'life', 'like', '?'], 'campus_life'), (['Tell', 'me', 'about', 'student', 'activities'], 'campus_life'), (['Are', 'there', 'clubs', 'on', 'campus', '?'], 'campus_life'), (['Is', 'housing', 'available', 'for', 'freshmen', '?'], 'housing'), (['What', 'are', 'the', 'housing', 'options', '?'], 'housing'), (['Tell', 'me', 'about', 'dormitories'], 'housing'), (['Tell', 'me', 'about', 'staying', 'options'], 'housing'), (['What', 'support', 'services', 'are', 'available', 'for', 'students', '?'], 'support_services'), (['Is', 'there', 'academic', 'advising', '?'], 'support_services'), (['Are', 'there', 'counseling', 'services', '?'], 'support_services'), (['Are', 'there', 'internship', 'opportunities', '?'], 'internships'), (['Can', 'I', 'do', 'internships', 'during', 'college', '?'], 'internships'), (['Tell', 'me', 'about', 'work-study', 'programs'], 'internships'), (['Tell', 'me', 'about', 'the', 'faculty'], 'faculty'), (['Are', 'the', 'professors', 'helpful', '?'], 'faculty'), (['Do', 'professors', 'offer', 'office', 'hours', '?'], 'faculty'), (['Are', 'there', 'study', 'abroad', 'programs', '?'], 'study_abroad'), (['Can', 'I', 'study', 'abroad', 'during', 'college', '?'], 'study_abroad'), (['Tell', 'me', 'about', 'exchange', 'programs'], 'study_abroad'), (['What', 'is', 'the', 'diversity', 'of', 'the', 'student', 'body', '?'], 'diversity'), (['Tell', 'me', 'about', 'diversity', 'on', 'campus'], 'diversity'), (['Are', 'there', 'international', 'students', '?'], 'diversity'), (['Is', 'there', 'an', 'admission', 'interview', '?'], 'admission_interview'), (['What', 'is', 'the', 'interview', 'process', 'like', '?'], 'admission_interview'), (['Tell', 'me', 'about', 'admission', 'interviews'], 'admission_interview'), (['Do', 'you', 'have', 'any', 'tips', 'for', 'the', 'application', 'process', '?'], 'application_tips'), (['How', 'can', 'I', 'improve', 'my', 'application', '?'], 'application_tips'), (['Tell', 'me', 'about', 'application', 'strategies'], 'application_tips'), (['What', 'standardized', 'tests', 'are', 'required', '?'], 'admission_tests'), (['Do', 'I', 'need', 'to', 'take', 'the', 'SAT', 'or', 'ACT', '?'], 'admission_tests'), (['Tell', 'me', 'about', 'admission', 'exams'], 'admission_tests'), (['How', 'much', 'does', 'it', 'cost', 'to', 'attend', '?'], 'financial_planning'), (['What', 'is', 'the', 'tuition', 'fee', '?'], 'financial_planning'), (['Tell', 'me', 'about', 'financial', 'planning', 'for', 'college'], 'financial_planning'), (['How', 'can', 'I', 'check', 'my', 'admission', 'status', '?'], 'admission_status'), (['When', 'will', 'I', 'hear', 'back', 'from', 'the', 'college', '?'], 'admission_status'), (['Tell', 'me', 'about', 'admission', 'decisions'], 'admission_status'), (['Is', 'there', 'an', 'application', 'fee', '?'], 'application_fee'), (['How', 'much', 'is', 'the', 'application', 'fee', '?'], 'application_fee'), (['Tell', 'me', 'about', 'application', 'fees'], 'application_fee'), (['Are', 'there', 'tutoring', 'services', 'available', '?'], 'academic_support'), (['Can', 'I', 'get', 'help', 'with', 'my', 'studies', '?'], 'academic_support'), (['Tell', 'me', 'about', 'academic', 'support'], 'academic_support'), (['Are', 'there', 'career', 'services', 'available', '?'], 'career_services'), (['Can', 'I', 'get', 'help', 'with', 'job', 'placement', '?'], 'career_services'), (['Tell', 'me', 'about', 'career', 'resources'], 'career_services'), (['Are', 'there', 'extracurricular', 'activities', '?'], 'student_activities'), (['Tell', 'me', 'about', 'student', 'clubs', 'and', 'organizations'], 'student_activities'), (['What', 'activities', 'can', 'I', 'participate', 'in', '?'], 'student_activities'), (['Are', 'there', 'health', 'services', 'available', 'on', 'campus', '?'], 'health_services'), (['Can', 'I', 'access', 'medical', 'care', '?'], 'health_services'), (['Tell', 'me', 'about', 'health', 'resources'], 'health_services'), (['When', 'is', 'the', 'deadline', 'to', 'apply', 'for', 'scholarships', '?'], 'scholarship_deadline'), (['Tell', 'me', 'about', 'scholarship', 'deadlines'], 'scholarship_deadline'), (['How', 'can', 'I', 'apply', 'for', 'scholarships', '?'], 'scholarship_deadline'), (['What', 'is', 'the', 'college', \"'s\", 'official', 'website', '?'], 'admission_website'), (['Where', 'can', 'I', 'find', 'more', 'information', 'about', 'admissions', '?'], 'admission_website'), (['Tell', 'me', 'about', 'the', 'admissions', 'website'], 'admission_website'), (['How', 'do', 'I', 'apply', '?'], 'application_process'), (['Tell', 'me', 'about', 'the', 'application', 'process'], 'application_process'), (['What', 'steps', 'do', 'I', 'need', 'to', 'take', 'to', 'apply', '?'], 'application_process'), (['How', 'do', 'I', 'apply', 'for', 'financial', 'aid', '?'], 'financial_aid_application'), (['Tell', 'me', 'about', 'the', 'financial', 'aid', 'application', 'process'], 'financial_aid_application'), (['What', 'forms', 'do', 'I', 'need', 'to', 'submit', 'for', 'financial', 'aid', '?'], 'financial_aid_application'), (['Are', 'there', 'online', 'resources', 'available', 'for', 'applicants', '?'], 'online_resources'), (['Tell', 'me', 'about', 'online', 'application', 'resources'], 'online_resources'), (['Where', 'can', 'I', 'find', 'help', 'online', '?'], 'online_resources')]\n"
     ]
    }
   ],
   "source": [
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'s\", 'about', 'abroad', 'academic', 'access', 'act', 'activity', 'admission', 'advising', 'afford', 'aid', 'an', 'and', 'any', 'applicant', 'application', 'apply', 'are', 'attend', 'available', 'back', 'body', 'bye', 'campus', 'can', 'care', 'career', 'check', 'club', 'college', 'cost', 'counseling', 'course', 'day', 'deadline', 'decision', 'diversity', 'do', 'document', 'doe', 'dormitory', 'during', 'exam', 'exchange', 'extracurricular', 'faculty', 'fee', 'financial', 'find', 'for', 'form', 'freshman', 'from', 'get', 'good', 'goodbye', 'have', 'health', 'hear', 'hello', 'help', 'helpful', 'helping', 'hey', 'hi', 'hour', 'housing', 'how', 'i', 'improve', 'in', 'information', 'international', 'internship', 'interview', 'is', 'it', 'job', 'later', 'life', 'like', 'list', 'major', 'me', 'medical', 'more', 'much', 'my', 'need', 'next', 'of', 'offer', 'offered', 'office', 'official', 'on', 'online', 'opportunity', 'option', 'or', 'organization', 'participate', 'placement', 'planning', 'process', 'professor', 'program', 'required', 'requirement', 'resource', 'sat', 'scholarship', 'see', 'service', 'standardized', 'status', 'staying', 'step', 'strategy', 'student', 'study', 'submit', 'support', 'take', 'tell', 'test', 'thank', 'thanks', 'that', 'the', 'there', 'till', 'time', 'tip', 'to', 'tuition', 'tutoring', 'website', 'what', 'when', 'where', 'will', 'with', 'work-study', 'you']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    # Initialize bag of words\n",
    "    bag = []\n",
    "    # Lemmatize each word\n",
    "    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in doc[0]]\n",
    "    # Create bag of words array\n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "        # Fills `bag` with `1` if the word appears in the document, else `0`.\n",
    "        \n",
    "    # Create output array\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "    \n",
    "    training.append([bag, output_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n"
     ]
    }
   ],
   "source": [
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n"
     ]
    }
   ],
   "source": [
    "print(len(training[1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creates an empty bag-of-words representation.\n",
    "- Lemmatizes words in the current document.\n",
    "- Fills `bag` with `1` if the word appears in the document, else `0`.\n",
    "- Creates a one-hot encoded output array for the intent tag.\n",
    "- Appends the `bag` (input) and `output_row` (label) to `training`.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data and convert to numpy arrays\n",
    "random.shuffle(training)\n",
    "training = np.array(training, dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Randomly shuffles data to prevent bias.\n",
    "-   Converts `training` list into a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data created\n"
     ]
    }
   ],
   "source": [
    "# Create train and test lists\n",
    "train_x = np.array(list(training[:, 0]))\n",
    "train_y = np.array(list(training[:, 1]))\n",
    "\n",
    "print(\"Training data created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Splits `training` data into `train_x` (features) and `train_y` (labels).\n",
    "- Confirms successful data preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Creating and Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_y[0]), activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `Sequential()` – Defines a feed-forward neural network.\n",
    "-   `Dense(128, input_shape=(len(train_x[0]),), activation='relu')` – Adds a fully connected layer with 128 neurons and ReLU activation.\n",
    "-   `Dropout(0.5)` – Prevents overfitting by randomly deactivating neurons.\n",
    "-   `Dense(64, activation='relu')` – Adds another hidden layer with 64 neurons.\n",
    "-   `Dense(len(train_y[0]), activation='softmax')` – Outputs probability distribution over intent classes.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# defining SGD optimizer\n",
    "sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Uses **Stochastic Gradient Descent (SGD)** as the optimizer.\n",
    "-   `categorical_crossentropy` is the loss function (used for multi-class classification).\n",
    "- `momentum=0.9`: Adds a fraction of the previous update to the current update to accelerate the gradient vectors in the right directions, thus leading to faster converging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0524 - loss: 3.3831    \n",
      "Epoch 2/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1300 - loss: 3.2113\n",
      "Epoch 3/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1127 - loss: 3.1196   \n",
      "Epoch 4/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1464 - loss: 2.8798   \n",
      "Epoch 5/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2456 - loss: 2.7038\n",
      "Epoch 6/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2959 - loss: 2.3857\n",
      "Epoch 7/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2757 - loss: 2.5430   \n",
      "Epoch 8/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3890 - loss: 2.2190\n",
      "Epoch 9/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4088 - loss: 2.1661   \n",
      "Epoch 10/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4717 - loss: 1.9025\n",
      "Epoch 11/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5638 - loss: 1.7650\n",
      "Epoch 12/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6200 - loss: 1.7133\n",
      "Epoch 13/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5741 - loss: 1.6532\n",
      "Epoch 14/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6578 - loss: 1.4109  \n",
      "Epoch 15/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6439 - loss: 1.3757\n",
      "Epoch 16/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6952 - loss: 1.1907\n",
      "Epoch 17/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6600 - loss: 1.2633\n",
      "Epoch 18/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6950 - loss: 1.2052\n",
      "Epoch 19/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6487 - loss: 1.2488\n",
      "Epoch 20/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6767 - loss: 1.1085\n",
      "Epoch 21/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6902 - loss: 0.9178\n",
      "Epoch 22/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7842 - loss: 0.8161\n",
      "Epoch 23/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7497 - loss: 0.8037\n",
      "Epoch 24/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7755 - loss: 0.8586\n",
      "Epoch 25/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8356 - loss: 0.5950\n",
      "Epoch 26/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7644 - loss: 0.9144\n",
      "Epoch 27/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8558 - loss: 0.5454\n",
      "Epoch 28/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7997 - loss: 0.6543\n",
      "Epoch 29/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7108 - loss: 0.8401\n",
      "Epoch 30/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.5870\n",
      "Epoch 31/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7752 - loss: 0.6693\n",
      "Epoch 32/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.4341\n",
      "Epoch 33/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8761 - loss: 0.4668\n",
      "Epoch 34/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7508 - loss: 0.5746\n",
      "Epoch 35/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7596 - loss: 0.5541\n",
      "Epoch 36/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8902 - loss: 0.4358\n",
      "Epoch 37/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8401 - loss: 0.5297\n",
      "Epoch 38/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8658 - loss: 0.4124  \n",
      "Epoch 39/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9204 - loss: 0.2920\n",
      "Epoch 40/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9059 - loss: 0.3173\n",
      "Epoch 41/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8319 - loss: 0.4600\n",
      "Epoch 42/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9546 - loss: 0.2745\n",
      "Epoch 43/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9189 - loss: 0.2800\n",
      "Epoch 44/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8841 - loss: 0.2996\n",
      "Epoch 45/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9386 - loss: 0.3352\n",
      "Epoch 46/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9438 - loss: 0.2874\n",
      "Epoch 47/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8978 - loss: 0.3174\n",
      "Epoch 48/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9420 - loss: 0.2589\n",
      "Epoch 49/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9400 - loss: 0.2486\n",
      "Epoch 50/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9203 - loss: 0.2255\n",
      "Epoch 51/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9461 - loss: 0.1749\n",
      "Epoch 52/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9811 - loss: 0.1663\n",
      "Epoch 53/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8874 - loss: 0.3161\n",
      "Epoch 54/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9261 - loss: 0.3028\n",
      "Epoch 55/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8964 - loss: 0.2646\n",
      "Epoch 56/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8725 - loss: 0.2877\n",
      "Epoch 57/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9423 - loss: 0.2008 \n",
      "Epoch 58/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9501 - loss: 0.3009\n",
      "Epoch 59/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9429 - loss: 0.2366\n",
      "Epoch 60/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9057 - loss: 0.2864\n",
      "Epoch 61/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9503 - loss: 0.1986\n",
      "Epoch 62/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9397 - loss: 0.2193\n",
      "Epoch 63/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9758 - loss: 0.1601\n",
      "Epoch 64/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9193 - loss: 0.2718\n",
      "Epoch 65/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8794 - loss: 0.2962\n",
      "Epoch 66/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9485 - loss: 0.1755\n",
      "Epoch 67/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9579 - loss: 0.1241\n",
      "Epoch 68/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9329 - loss: 0.2249\n",
      "Epoch 69/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9377 - loss: 0.2230\n",
      "Epoch 70/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9779 - loss: 0.1410 \n",
      "Epoch 71/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9648 - loss: 0.1343\n",
      "Epoch 72/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9534 - loss: 0.1332\n",
      "Epoch 73/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9983 - loss: 0.0980 \n",
      "Epoch 74/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9812 - loss: 0.0871\n",
      "Epoch 75/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9559 - loss: 0.1949\n",
      "Epoch 76/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9371 - loss: 0.2282\n",
      "Epoch 77/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9092 - loss: 0.3183\n",
      "Epoch 78/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9032 - loss: 0.1877 \n",
      "Epoch 79/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.1042\n",
      "Epoch 80/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9546 - loss: 0.2102  \n",
      "Epoch 81/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9773 - loss: 0.1076\n",
      "Epoch 82/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9239 - loss: 0.2596\n",
      "Epoch 83/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9704 - loss: 0.0994\n",
      "Epoch 84/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9735 - loss: 0.1189 \n",
      "Epoch 85/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.1173\n",
      "Epoch 86/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9411 - loss: 0.2064\n",
      "Epoch 87/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9212 - loss: 0.2353\n",
      "Epoch 88/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9645 - loss: 0.1261\n",
      "Epoch 89/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9277 - loss: 0.2854\n",
      "Epoch 90/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9755 - loss: 0.1487 \n",
      "Epoch 91/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9885 - loss: 0.1451\n",
      "Epoch 92/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9502 - loss: 0.1364\n",
      "Epoch 93/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9472 - loss: 0.12259e-\n",
      "Epoch 94/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2083\n",
      "Epoch 95/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.1899\n",
      "Epoch 96/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9520 - loss: 0.2156\n",
      "Epoch 97/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9653 - loss: 0.1239\n",
      "Epoch 98/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9126 - loss: 0.4522\n",
      "Epoch 99/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9087 - loss: 0.2293\n",
      "Epoch 100/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9396 - loss: 0.1515  \n",
      "Epoch 101/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9755 - loss: 0.1231\n",
      "Epoch 102/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9503 - loss: 0.1423\n",
      "Epoch 103/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9961 - loss: 0.0846   \n",
      "Epoch 104/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9712 - loss: 0.1295\n",
      "Epoch 105/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9717 - loss: 0.1675\n",
      "Epoch 106/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9807 - loss: 0.0570\n",
      "Epoch 107/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9743 - loss: 0.0832  \n",
      "Epoch 108/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9721 - loss: 0.1042  \n",
      "Epoch 109/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9856 - loss: 0.0754\n",
      "Epoch 110/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.1778\n",
      "Epoch 111/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9604 - loss: 0.1291\n",
      "Epoch 112/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9319 - loss: 0.1620\n",
      "Epoch 113/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9731 - loss: 0.0838\n",
      "Epoch 114/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9049 - loss: 0.2842\n",
      "Epoch 115/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9834 - loss: 0.1600  \n",
      "Epoch 116/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9714 - loss: 0.1273\n",
      "Epoch 117/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9531 - loss: 0.1457\n",
      "Epoch 118/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9286 - loss: 0.2339\n",
      "Epoch 119/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9551 - loss: 0.1018\n",
      "Epoch 120/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2029\n",
      "Epoch 121/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9787 - loss: 0.0884\n",
      "Epoch 122/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9465 - loss: 0.1162\n",
      "Epoch 123/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9859 - loss: 0.0752     \n",
      "Epoch 124/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9398 - loss: 0.2161\n",
      "Epoch 125/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9344 - loss: 0.1366\n",
      "Epoch 126/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9587 - loss: 0.2181\n",
      "Epoch 127/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9800 - loss: 0.1419\n",
      "Epoch 128/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9860 - loss: 0.0915 \n",
      "Epoch 129/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9554 - loss: 0.1897\n",
      "Epoch 130/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9740 - loss: 0.1134\n",
      "Epoch 131/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9798 - loss: 0.0851\n",
      "Epoch 132/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.1362\n",
      "Epoch 133/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9240 - loss: 0.1659 \n",
      "Epoch 134/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9869 - loss: 0.0797   \n",
      "Epoch 135/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9658 - loss: 0.1054 \n",
      "Epoch 136/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9702 - loss: 0.0798\n",
      "Epoch 137/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9780 - loss: 0.1116\n",
      "Epoch 138/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9440 - loss: 0.1325   \n",
      "Epoch 139/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9613 - loss: 0.1049\n",
      "Epoch 140/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9381 - loss: 0.3345\n",
      "Epoch 141/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9189 - loss: 0.1331\n",
      "Epoch 142/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9560 - loss: 0.1359   \n",
      "Epoch 143/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9524 - loss: 0.2263\n",
      "Epoch 144/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9459 - loss: 0.1866\n",
      "Epoch 145/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9758 - loss: 0.0957\n",
      "Epoch 146/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9342 - loss: 0.1320\n",
      "Epoch 147/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9823 - loss: 0.0521\n",
      "Epoch 148/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9206 - loss: 0.1394\n",
      "Epoch 149/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9887 - loss: 0.0469  \n",
      "Epoch 150/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9765 - loss: 0.0644\n",
      "Epoch 151/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9623 - loss: 0.1695\n",
      "Epoch 152/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.1604\n",
      "Epoch 153/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9227 - loss: 0.1198\n",
      "Epoch 154/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9257 - loss: 0.2383\n",
      "Epoch 155/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9622 - loss: 0.0948\n",
      "Epoch 156/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9828 - loss: 0.0898\n",
      "Epoch 157/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9580 - loss: 0.0822\n",
      "Epoch 158/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9671 - loss: 0.1105 \n",
      "Epoch 159/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9474 - loss: 0.1435\n",
      "Epoch 160/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9897 - loss: 0.0464\n",
      "Epoch 161/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9941 - loss: 0.0551\n",
      "Epoch 162/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9954 - loss: 0.0314   \n",
      "Epoch 163/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9530 - loss: 0.0965\n",
      "Epoch 164/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9617 - loss: 0.1100\n",
      "Epoch 165/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0376\n",
      "Epoch 166/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9579 - loss: 0.1025\n",
      "Epoch 167/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9891 - loss: 0.0508 \n",
      "Epoch 168/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0265\n",
      "Epoch 169/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9921 - loss: 0.0879\n",
      "Epoch 170/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9663 - loss: 0.0792\n",
      "Epoch 171/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8937 - loss: 0.2545\n",
      "Epoch 172/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9640 - loss: 0.1551\n",
      "Epoch 173/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9736 - loss: 0.1735\n",
      "Epoch 174/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9500 - loss: 0.1356\n",
      "Epoch 175/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9752 - loss: 0.0905\n",
      "Epoch 176/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9861 - loss: 0.0731\n",
      "Epoch 177/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9904 - loss: 0.0384\n",
      "Epoch 178/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9797 - loss: 0.0410   \n",
      "Epoch 179/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9870 - loss: 0.07763e-\n",
      "Epoch 180/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9965 - loss: 0.0395e-0\n",
      "Epoch 181/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9635 - loss: 0.1524   \n",
      "Epoch 182/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0350\n",
      "Epoch 183/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9690 - loss: 0.1500\n",
      "Epoch 184/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9354 - loss: 0.2368\n",
      "Epoch 185/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9458 - loss: 0.2630\n",
      "Epoch 186/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9955 - loss: 0.0415\n",
      "Epoch 187/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.2450\n",
      "Epoch 188/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9815 - loss: 0.1294\n",
      "Epoch 189/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9961 - loss: 0.0737 \n",
      "Epoch 190/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9583 - loss: 0.1647\n",
      "Epoch 191/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9694 - loss: 0.1000\n",
      "Epoch 192/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9308 - loss: 0.1465  \n",
      "Epoch 193/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9591 - loss: 0.0722   \n",
      "Epoch 194/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9529 - loss: 0.0973 \n",
      "Epoch 195/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9812 - loss: 0.0681   \n",
      "Epoch 196/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9201 - loss: 0.2686\n",
      "Epoch 197/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9709 - loss: 0.1146\n",
      "Epoch 198/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9447 - loss: 0.1255   \n",
      "Epoch 199/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9018 - loss: 0.1587\n",
      "Epoch 200/200\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9941 - loss: 0.0810\n"
     ]
    }
   ],
   "source": [
    "# Fit and save the model\n",
    "hist = model.fit(train_x, train_y, epochs=200, batch_size=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Trains the model for **200 epochs** using mini-batches of size **5**.\n",
    "-   `verbose=1` prints training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created\n"
     ]
    }
   ],
   "source": [
    "model.save('Model/chatbot_model.h5', hist)\n",
    "print(\"Model created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Saves the trained model as `chatbot_model.h5`.\n",
    "- Confirms the successful creation of the model.\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Summary of Key Steps**\n",
    "\n",
    "1.  **Load and preprocess dataset** – Tokenization, lemmatization, and intent tagging.\n",
    "2.  **Create bag-of-words representations** – Convert text data into numerical format.\n",
    "3.  **Train a Neural Network** – Using dense layers and dropout to classify intent.\n",
    "4.  **Save model and preprocessing files** – To be used in chatbot inference.\n",
    "\n",
    "This is the complete breakdown of `train_model.py`. Let me know if you want to go deeper into any part! 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
