{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import tensorflow as tf\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Bidirectional, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GILNaVt447YM",
        "outputId": "1431c562-3586-4deb-d197-f23d3800ef0c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NZ0rgYiY422r"
      },
      "outputs": [],
      "source": [
        "class NewsSummarizer:\n",
        "    def __init__(self, max_news_length=500, max_summary_length=100, embedding_dim=256, lstm_units=256):\n",
        "        \"\"\"Initialize the news summarization model with given parameters.\"\"\"\n",
        "        self.max_news_length = max_news_length\n",
        "        self.max_summary_length = max_summary_length\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.lstm_units = lstm_units\n",
        "        self.news_tokenizer = None\n",
        "        self.summary_tokenizer = None\n",
        "        self.model = None\n",
        "        self.encoder_model = None\n",
        "        self.decoder_model = None\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        \"\"\"Clean and preprocess the input text\"\"\"\n",
        "        if isinstance(text, float) or text is None:  # Handle NaN values and None\n",
        "            return \"\"\n",
        "\n",
        "        # Convert to lowercase\n",
        "        text = str(text).lower()\n",
        "\n",
        "        # Remove URLs, HTML tags, numbers and punctuation\n",
        "        text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
        "        text = re.sub(r'<.*?>', '', text)\n",
        "        text = re.sub(r'\\d+', '', text)\n",
        "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "        # Remove extra whitespace\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "        return text\n",
        "\n",
        "    def load_dataset(self, filepath, num_samples=None):\n",
        "        \"\"\"Load and prepare the dataset\"\"\"\n",
        "        try:\n",
        "            # Load the dataset\n",
        "            df = pd.read_csv(filepath)\n",
        "\n",
        "            # Check if we want to limit the number of samples\n",
        "            if num_samples and num_samples < len(df):\n",
        "                df = df.sample(n=num_samples, random_state=42)\n",
        "\n",
        "            # Extract articles and summaries\n",
        "            news_articles = df['text'].tolist()\n",
        "            summaries = df['headlines'].tolist()\n",
        "\n",
        "            # Filter out any empty articles or summaries\n",
        "            valid_indices = [i for i, (article, summary) in enumerate(zip(news_articles, summaries))\n",
        "                            if isinstance(article, str) and isinstance(summary, str)\n",
        "                            and len(article.strip()) > 0 and len(summary.strip()) > 0]\n",
        "\n",
        "            news_articles = [news_articles[i] for i in valid_indices]\n",
        "            summaries = [summaries[i] for i in valid_indices]\n",
        "\n",
        "            print(f\"Loaded {len(news_articles)} valid articles with summaries\")\n",
        "\n",
        "            return news_articles, summaries\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading dataset: {e}\")\n",
        "            return [], []\n",
        "\n",
        "    def prepare_data(self, news_articles, summaries):\n",
        "        \"\"\"Prepare the data for training\"\"\"\n",
        "        if not news_articles or not summaries:\n",
        "            raise ValueError(\"Empty news articles or summaries list provided\")\n",
        "\n",
        "        # Preprocess news articles and summaries\n",
        "        processed_news = [self.preprocess_text(news) for news in news_articles]\n",
        "        processed_summaries = [self.preprocess_text(summary) for summary in summaries]\n",
        "\n",
        "        # Add start and end tokens to summaries\n",
        "        processed_summaries = ['startseq ' + summary + ' endseq' for summary in processed_summaries]\n",
        "\n",
        "        # Create tokenizers\n",
        "        self.news_tokenizer = Tokenizer()\n",
        "        self.news_tokenizer.fit_on_texts(processed_news)\n",
        "\n",
        "        self.summary_tokenizer = Tokenizer()\n",
        "        self.summary_tokenizer.fit_on_texts(processed_summaries)\n",
        "\n",
        "        # Get vocabulary sizes\n",
        "        news_vocab_size = len(self.news_tokenizer.word_index) + 1\n",
        "        summary_vocab_size = len(self.summary_tokenizer.word_index) + 1\n",
        "\n",
        "        # Convert texts to sequences\n",
        "        news_sequences = self.news_tokenizer.texts_to_sequences(processed_news)\n",
        "        summary_sequences = self.summary_tokenizer.texts_to_sequences(processed_summaries)\n",
        "\n",
        "        # Pad sequences\n",
        "        news_padded = pad_sequences(news_sequences, maxlen=self.max_news_length, padding='post')\n",
        "        summary_padded = pad_sequences(summary_sequences, maxlen=self.max_summary_length, padding='post')\n",
        "\n",
        "        # Split data into training and validation sets\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            news_padded, summary_padded, test_size=0.2, random_state=42\n",
        "        )\n",
        "\n",
        "        # Verify dimensions\n",
        "        print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
        "        print(f\"Validation data shape: {X_val.shape}, {y_val.shape}\")\n",
        "\n",
        "        return X_train, X_val, y_train, y_val, news_vocab_size, summary_vocab_size\n",
        "\n",
        "    def build_model(self, news_vocab_size, summary_vocab_size):\n",
        "        \"\"\"Build the sequence-to-sequence model with bidirectional LSTM\"\"\"\n",
        "        # Encoder\n",
        "        encoder_inputs = Input(shape=(self.max_news_length,), name='encoder_inputs')\n",
        "        encoder_embedding = Embedding(news_vocab_size, self.embedding_dim, name='encoder_embedding')(encoder_inputs)\n",
        "\n",
        "        # Bidirectional LSTM for encoder\n",
        "        encoder_bilstm = Bidirectional(LSTM(self.lstm_units, return_sequences=True, return_state=True), name='encoder_bilstm')\n",
        "        encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder_bilstm(encoder_embedding)\n",
        "\n",
        "        # Concatenate forward and backward states\n",
        "        state_h = Concatenate(name='concatenate_h')([forward_h, backward_h])\n",
        "        state_c = Concatenate(name='concatenate_c')([forward_c, backward_c])\n",
        "        encoder_states = [state_h, state_c]\n",
        "\n",
        "        # Decoder\n",
        "        decoder_inputs = Input(shape=(None,), name='decoder_inputs')\n",
        "        decoder_embedding = Embedding(summary_vocab_size, self.embedding_dim, name='decoder_embedding')(decoder_inputs)\n",
        "        decoder_lstm = LSTM(self.lstm_units * 2, return_sequences=True, return_state=True, name='decoder_lstm')\n",
        "        decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "\n",
        "        # Output projection\n",
        "        decoder_dense = Dense(summary_vocab_size, activation='softmax', name='decoder_dense')(decoder_outputs)\n",
        "\n",
        "        # Define the model\n",
        "        self.model = Model([encoder_inputs, decoder_inputs], decoder_dense)\n",
        "\n",
        "        # Compile the model\n",
        "        self.model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        return self.model\n",
        "\n",
        "    def train(self, X_train, X_val, y_train, y_val, batch_size=64, epochs=10):\n",
        "        \"\"\"Train the model\"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model must be built before training\")\n",
        "\n",
        "        # Create decoder input data (shifted by one step)\n",
        "        decoder_input_train = y_train[:, :-1]\n",
        "        decoder_target_train = y_train[:, 1:]\n",
        "\n",
        "        decoder_input_val = y_val[:, :-1]\n",
        "        decoder_target_val = y_val[:, 1:]\n",
        "\n",
        "        # Create callbacks\n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss', patience=3, restore_best_weights=True\n",
        "        )\n",
        "\n",
        "        # Train the model\n",
        "        history = self.model.fit(\n",
        "            [X_train, decoder_input_train],\n",
        "            tf.expand_dims(decoder_target_train, -1),\n",
        "            validation_data=([X_val, decoder_input_val], tf.expand_dims(decoder_target_val, -1)),\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            callbacks=[early_stopping],\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        return history\n",
        "\n",
        "    def infer_init(self):\n",
        "        \"\"\"Initialize inference models\"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model must be trained before initializing inference models\")\n",
        "\n",
        "        # Print all layers for debugging\n",
        "        print(\"Available layers in the model:\")\n",
        "        for i, layer in enumerate(self.model.layers):\n",
        "            print(f\"{i}: {layer.name}\")\n",
        "\n",
        "        try:\n",
        "            # Get the encoder inputs layer - this is a tensor now, not the layer itself\n",
        "            encoder_inputs = self.model.input[0]  # First input in the model (encoder_inputs)\n",
        "\n",
        "            # Find the bidirectional layer\n",
        "            encoder_bilstm = None\n",
        "            for layer in self.model.layers:\n",
        "                if isinstance(layer, Bidirectional):\n",
        "                    encoder_bilstm = layer\n",
        "                    print(f\"Found bidirectional layer: {layer.name}\")\n",
        "                    break\n",
        "\n",
        "            if encoder_bilstm is None:\n",
        "                raise ValueError(\"Could not find bidirectional layer in the model\")\n",
        "\n",
        "            # Get the encoder embedding layer\n",
        "            encoder_embedding = self.model.get_layer('encoder_embedding')\n",
        "\n",
        "            # Create a new input tensor for the encoder model\n",
        "            encoder_model_input = Input(shape=(self.max_news_length,), name='encoder_model_input')\n",
        "\n",
        "            # Apply the embedding layer to the new input\n",
        "            encoder_embedded = encoder_embedding(encoder_model_input)\n",
        "\n",
        "            # Apply the bidirectional LSTM\n",
        "            _, forward_h, forward_c, backward_h, backward_c = encoder_bilstm(encoder_embedded)\n",
        "\n",
        "            # Concatenate the states\n",
        "            state_h = Concatenate(name='encoder_model_concat_h')([forward_h, backward_h])\n",
        "            state_c = Concatenate(name='encoder_model_concat_c')([forward_c, backward_c])\n",
        "\n",
        "            # Create encoder model\n",
        "            self.encoder_model = Model(encoder_model_input, [state_h, state_c])\n",
        "\n",
        "            # Create decoder model\n",
        "            decoder_inputs = Input(shape=(1,), name='inference_decoder_inputs')\n",
        "            decoder_state_h = Input(shape=(self.lstm_units * 2,), name='inference_decoder_state_h')\n",
        "            decoder_state_c = Input(shape=(self.lstm_units * 2,), name='inference_decoder_state_c')\n",
        "\n",
        "            decoder_embedding = self.model.get_layer('decoder_embedding')\n",
        "            decoder_lstm = self.model.get_layer('decoder_lstm')\n",
        "            decoder_dense = self.model.get_layer('decoder_dense')\n",
        "\n",
        "            decoder_embedding_out = decoder_embedding(decoder_inputs)\n",
        "            decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "                decoder_embedding_out, initial_state=[decoder_state_h, decoder_state_c]\n",
        "            )\n",
        "\n",
        "            decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "            self.decoder_model = Model(\n",
        "                [decoder_inputs, decoder_state_h, decoder_state_c],\n",
        "                [decoder_outputs, state_h, state_c]\n",
        "            )\n",
        "\n",
        "            print(\"Inference models initialized successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            import traceback\n",
        "            print(f\"Error in infer_init: {e}\")\n",
        "            print(traceback.format_exc())\n",
        "            raise\n",
        "\n",
        "    def generate_summary(self, news_article, max_length=100):\n",
        "        \"\"\"Generate a summary for a news article\"\"\"\n",
        "        if self.encoder_model is None or self.decoder_model is None:\n",
        "            raise ValueError(\"Inference models must be initialized before generating summaries\")\n",
        "\n",
        "        # Preprocess input\n",
        "        processed_article = self.preprocess_text(news_article)\n",
        "\n",
        "        # Convert to sequence and pad\n",
        "        article_seq = self.news_tokenizer.texts_to_sequences([processed_article])\n",
        "        if not article_seq[0]:  # Check if sequence is empty\n",
        "            return \"Unable to generate summary: input text contains no recognized tokens.\"\n",
        "\n",
        "        article_padded = pad_sequences(article_seq, maxlen=self.max_news_length, padding='post')\n",
        "\n",
        "        try:\n",
        "            # Encode the input\n",
        "            state_h, state_c = self.encoder_model.predict(article_padded, verbose=0)\n",
        "\n",
        "            # Get start token\n",
        "            target_seq = np.zeros((1, 1))\n",
        "            start_token_idx = self.summary_tokenizer.word_index.get('startseq')\n",
        "            if not start_token_idx:\n",
        "                raise ValueError(\"Start token not found in tokenizer\")\n",
        "\n",
        "            target_seq[0, 0] = start_token_idx\n",
        "\n",
        "            # Initialize result\n",
        "            result = []\n",
        "            stop_condition = False\n",
        "\n",
        "            while not stop_condition:\n",
        "                # Predict next token\n",
        "                output_tokens, h, c = self.decoder_model.predict([target_seq, state_h, state_c], verbose=0)\n",
        "\n",
        "                # Get predicted token\n",
        "                sampled_token_index = np.argmax(output_tokens[0, 0, :])\n",
        "\n",
        "                # Convert token to word\n",
        "                sampled_word = None\n",
        "                for word, index in self.summary_tokenizer.word_index.items():\n",
        "                    if index == sampled_token_index:\n",
        "                        sampled_word = word\n",
        "                        break\n",
        "\n",
        "                if sampled_word is None:\n",
        "                    break\n",
        "\n",
        "                # Check for end token\n",
        "                if sampled_word == 'endseq' or len(result) >= max_length:\n",
        "                    stop_condition = True\n",
        "                else:\n",
        "                    result.append(sampled_word)\n",
        "\n",
        "                # Update target sequence\n",
        "                target_seq = np.zeros((1, 1))\n",
        "                target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "                # Update states\n",
        "                state_h, state_c = h, c\n",
        "\n",
        "            return ' '.join(result)\n",
        "        except Exception as e:\n",
        "            import traceback\n",
        "            print(f\"Error generating summary: {e}\")\n",
        "            print(traceback.format_exc())\n",
        "            return f\"Error generating summary: {str(e)}\"\n",
        "\n",
        "    def save_model(self, filepath):\n",
        "        \"\"\"Save the model to a file\"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"No model to save\")\n",
        "\n",
        "        try:\n",
        "            # Save main model\n",
        "            self.model.save(filepath + '.keras')\n",
        "\n",
        "            # Save tokenizers\n",
        "            import pickle\n",
        "            with open(filepath + '_news_tokenizer.pkl', 'wb') as f:\n",
        "                pickle.dump(self.news_tokenizer, f)\n",
        "\n",
        "            with open(filepath + '_summary_tokenizer.pkl', 'wb') as f:\n",
        "                pickle.dump(self.summary_tokenizer, f)\n",
        "\n",
        "            print(f\"Model saved successfully to {filepath}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving model: {e}\")\n",
        "            return False\n",
        "\n",
        "    def load_model(self, filepath):\n",
        "        \"\"\"Load the model from a file\"\"\"\n",
        "        try:\n",
        "            # Load main model\n",
        "            self.model = tf.keras.models.load_model(filepath + '.keras')\n",
        "\n",
        "            # Load tokenizers\n",
        "            import pickle\n",
        "            with open(filepath + '_news_tokenizer.pkl', 'rb') as f:\n",
        "                self.news_tokenizer = pickle.load(f)\n",
        "\n",
        "            with open(filepath + '_summary_tokenizer.pkl', 'rb') as f:\n",
        "                self.summary_tokenizer = pickle.load(f)\n",
        "\n",
        "            print(f\"Model loaded successfully from {filepath}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model: {e}\")\n",
        "            return False\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Main execution function\n",
        "def run_summarizer(dataset_path, num_samples=None):\n",
        "    # Configuration parameters\n",
        "    MAX_NEWS_LENGTH = 500\n",
        "    MAX_SUMMARY_LENGTH = 100\n",
        "    EMBEDDING_DIM = 256\n",
        "    LSTM_UNITS = 256\n",
        "    BATCH_SIZE = 64\n",
        "    EPOCHS = 10\n",
        "\n",
        "    # Initialize the summarizer\n",
        "    summarizer = NewsSummarizer(\n",
        "        max_news_length=MAX_NEWS_LENGTH,\n",
        "        max_summary_length=MAX_SUMMARY_LENGTH,\n",
        "        embedding_dim=EMBEDDING_DIM,\n",
        "        lstm_units=LSTM_UNITS\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        # Load and prepare the dataset\n",
        "        print(\"Loading dataset...\")\n",
        "        news_articles, summaries = summarizer.load_dataset(dataset_path, num_samples=num_samples)\n",
        "\n",
        "        if not news_articles or not summaries:\n",
        "            print(\"No valid data loaded. Exiting.\")\n",
        "            return None\n",
        "\n",
        "        print(\"Preparing data...\")\n",
        "        X_train, X_val, y_train, y_val, news_vocab_size, summary_vocab_size = summarizer.prepare_data(\n",
        "            news_articles, summaries\n",
        "        )\n",
        "\n",
        "        # Build model\n",
        "        print(\"Building model...\")\n",
        "        model = summarizer.build_model(news_vocab_size, summary_vocab_size)\n",
        "        print(model.summary())\n",
        "\n",
        "        # Train model\n",
        "        print(\"Training model...\")\n",
        "        history = summarizer.train(\n",
        "            X_train, X_val, y_train, y_val,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            epochs=EPOCHS\n",
        "        )\n",
        "\n",
        "        # Save model\n",
        "        print(\"Saving model...\")\n",
        "        summarizer.save_model(\"news_summarizer_model\")\n",
        "\n",
        "        # Initialize inference models\n",
        "        print(\"Initializing inference models...\")\n",
        "        summarizer.infer_init()\n",
        "\n",
        "        # Example summary generation\n",
        "        print(\"Generating sample summaries...\")\n",
        "        for i in range(min(3, len(news_articles))):  # Generate for up to 3 sample articles\n",
        "            article = news_articles[i]\n",
        "            original_summary = summaries[i]\n",
        "            generated_summary = summarizer.generate_summary(article)\n",
        "\n",
        "            print(f\"\\nOriginal Article: {article[:100]}...\")\n",
        "            print(f\"Original Summary: {original_summary}\")\n",
        "            print(f\"Generated Summary: {generated_summary}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "        return summarizer\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        print(f\"Error in run_summarizer: {e}\")\n",
        "        print(traceback.format_exc())  # Print the full stack trace for better debugging\n",
        "        return None\n",
        "\n",
        "# Run if executed directly\n",
        "if __name__ == \"__main__\":\n",
        "    run_summarizer('news_summary_more.csv', num_samples=1000)  # Limit to 1000 samples for faster training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tEuP4Ggz5OIu",
        "outputId": "d2577d74-8533-4187-a3be-bf181e231d05"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Loaded 1000 valid articles with summaries\n",
            "Preparing data...\n",
            "Training data shape: (800, 500), (800, 100)\n",
            "Validation data shape: (200, 500), (200, 100)\n",
            "Building model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ encoder_embedding         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m2,597,632\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ encoder_bilstm            │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m512\u001b[0m),     │      \u001b[38;5;34m1,050,624\u001b[0m │ encoder_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │                        │\n",
              "│                           │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     │                │                        │\n",
              "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]           │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_embedding         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m990,976\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_h             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ encoder_bilstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],  │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ encoder_bilstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m3\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_c             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ encoder_bilstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m],  │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ encoder_bilstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m4\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),    │      \u001b[38;5;34m1,574,912\u001b[0m │ decoder_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │ concatenate_h[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │ \u001b[38;5;34m512\u001b[0m)]                  │                │ concatenate_c[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_dense (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3871\u001b[0m)     │      \u001b[38;5;34m1,985,823\u001b[0m │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ encoder_embedding         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,597,632</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ encoder_bilstm            │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │ encoder_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │                        │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     │                │                        │\n",
              "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]           │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_embedding         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">990,976</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_h             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_bilstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ encoder_bilstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_c             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_bilstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ encoder_bilstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ decoder_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │ concatenate_h[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]                  │                │ concatenate_c[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3871</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,985,823</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,199,967\u001b[0m (31.28 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,199,967</span> (31.28 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,199,967\u001b[0m (31.28 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,199,967</span> (31.28 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Training model...\n",
            "Epoch 1/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - accuracy: 0.6879 - loss: 5.1224 - val_accuracy: 0.8973 - val_loss: 1.0623\n",
            "Epoch 2/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - accuracy: 0.8923 - loss: 1.0188 - val_accuracy: 0.8873 - val_loss: 1.0130\n",
            "Epoch 3/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 183ms/step - accuracy: 0.8895 - loss: 0.9531 - val_accuracy: 0.8989 - val_loss: 0.8134\n",
            "Epoch 4/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 187ms/step - accuracy: 0.8996 - loss: 0.7734 - val_accuracy: 0.9007 - val_loss: 0.7659\n",
            "Epoch 5/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 188ms/step - accuracy: 0.9010 - loss: 0.7329 - val_accuracy: 0.9047 - val_loss: 0.7552\n",
            "Epoch 6/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 186ms/step - accuracy: 0.9043 - loss: 0.7131 - val_accuracy: 0.9068 - val_loss: 0.7555\n",
            "Epoch 7/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 189ms/step - accuracy: 0.9077 - loss: 0.6991 - val_accuracy: 0.9092 - val_loss: 0.7570\n",
            "Epoch 8/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 187ms/step - accuracy: 0.9091 - loss: 0.6933 - val_accuracy: 0.9094 - val_loss: 0.7587\n",
            "Saving model...\n",
            "Model saved successfully to news_summarizer_model\n",
            "Initializing inference models...\n",
            "Available layers in the model:\n",
            "0: encoder_inputs\n",
            "1: encoder_embedding\n",
            "2: decoder_inputs\n",
            "3: encoder_bilstm\n",
            "4: decoder_embedding\n",
            "5: concatenate_h\n",
            "6: concatenate_c\n",
            "7: decoder_lstm\n",
            "8: decoder_dense\n",
            "Found bidirectional layer: encoder_bilstm\n",
            "Inference models initialized successfully\n",
            "Generating sample summaries...\n",
            "\n",
            "Original Article: Students in Karnataka will get extra marks if their parents cast votes in the upcoming assembly elec...\n",
            "Original Summary: K'taka students to get extra marks if parents vote in polls\n",
            "Generated Summary: to to to to to to to\n",
            "--------------------------------------------------\n",
            "\n",
            "Original Article: Syrian anti-aircraft defences on Monday shot down missiles over two air bases, Syria's state media s...\n",
            "Original Summary: Syria shoots down missiles fired at two air bases\n",
            "Generated Summary: to to to to to to to\n",
            "--------------------------------------------------\n",
            "\n",
            "Original Article: A Dinosaur-like creature's fossil was found during an excavation on Sunday in Uttarakhand's Jaspur, ...\n",
            "Original Summary: Dinosaur-like animal's fossil found in Uttarakhand\n",
            "Generated Summary: to to to to to to to\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}