# Project Submissions

## Ramesh Prajapat - AttendAI [ðŸ”—GitHub Link](https://github.com/PRAJAPATBOI/AttendAI)

**Description:** AttendAI is an intelligent attendance tracking system that uses facial recognition technology to automate the attendance recording process. Built with Python, Tkinter, and OpenCV, this application captures student/employee images, trains a recognition model, and marks attendance by identifying registered individuals through a webcam. AttendAI eliminates manual attendance-taking, prevents proxy attendance, and maintains digital attendance records with timestamps.

## Khushwant Mehra - WordScan [ðŸ”—GitHub Link](https://github.com/This-is-khushwant/WordScan)

**Description:** WordScan is a Python-based application designed to process document photos by enhancing the text within them. It extracts text from images and provides summaries, making it easier to understand, analyze and digitalize the content.

## Yuvraj Singh - Face Tracker WebCam with Gesture Controls [ðŸ”—GitHub Link](https://github.com/himeshnama007/WasteClassificationModel)

**Description:** This project implements AI-powered smooth face tracking, hand gesture-based controls, and a virtual writing pad using OpenCV and MediaPipe. The system detects faces and adjusts the viewport dynamically with exponential smoothing and zoom control based on face size.

## Pankaj Kumar Goyal - Mental Health Guardian [ðŸ”—GitHub Link](https://github.com/Pankaj4152/Mental-Health-Guardian)

**Description:** Mental Health Guardian is a proactive web application that analyzes social media activity to detect potential signs of emotional distress. Leveraging NLP (Natural Language Processing) and Twitter/X API integration, it scans posts for concerning language patterns, negative sentiment trends, and crisis-related keywords. The tool provides actionable insights through an intuitive dashboard, including sentiment visualizations, risk-level assessments, and support recommendations, enabling early intervention for mental health awareness. Built with Python/Flask and modern web technologies, it serves as a proof-of-concept for AI-driven social media well-being monitoring.

## Pawan Kumar - Resume parser and job maching [ðŸ”—GitHub Link](https://github.com/Kpawankumar/Resume-parser-and-job-maching)

**Description:** Resume Matcher is a Python-based tool that extracts key details (education, experience, and skills) from resumes (PDF/DOCX) using NLP and matches them with job descriptions using TF-IDF and cosine similarity, providing a relevance score.

## Garvit Chourasia - Plant disease detection [ðŸ”—GitHub Link](https://github.com/garvit1420/Plant-disease-detection)

**Description:** This project is a Flask-based web application for detecting apple leaf diseases using a deep learning model. It can classify uploaded leaf images into three categories: Apple Scab, Black Rot, or healthy, and provides detailed treatment recommendations for each disease. The system includes bias detection and correction mechanisms to ensure accurate predictions, along with robust image preprocessing. Designed for farmers/gardeners, it offers an easy-to-use interface for disease diagnosis and management advice.

## Ayush Singh Rao - AI Summarizer [ðŸ”—GitHub Link](https://github.com/Ayush-S-Rao/10_Days-AI-Workshop)

**Description:** summarises web articles and youtube videos transcript

## Udit Navariya - AI-Powered Deepfake Detection System [ðŸ”—GitHub Link](https://github.com/udit-gitops/finalkafinal)

**Description:** This project utilizes Neural Networks, OpenCV, and NLP to detect deepfake images and videos with high accuracy. The system analyzes media files using deep learning techniques to differentiate between authentic and manipulated content. It processes uploaded files in real-time and provides a confidence score indicating the likelihood of deepfake manipulation. This project showcases the application of AI in cybersecurity and digital forensics, addressing the growing concern of synthetic media in today's digital landscape.

## Preeti Deora - QR_CODE_AUTHENTICATOR [ðŸ”—GitHub Link](https://github.com/Preeti-deora/QR_CODE_AUTHENTICATOR)

**Description:** This project finds whether a QR code is counterfeit or genuine

## Sidharth Joshi - Kicklytics - Football Anaylytics [ðŸ”—GitHub Link](https://github.com/sidharth031/Kicklytics31)

**Description:** This project analyzes football match videos to track players, assign teams, determine ball possession referees, and footballs. It uses YOLO-based object detection, tracking algorithms, and custom logic for team and ball assignment.

## Hansika Chaudhry - Document Analyser Tool [ðŸ”—GitHub Link](https://github.com/Hansika-codex143/Project.git)

**Description:** A comprehensive application designed to analyse various types of documents (text files, PDFs, images) and provide multiple analysis features including OCR, summarization, legal clause detection, translation, plagiarism checking, and more

## SAKSHI SHEKHAWAT - GESTURE RECOGNITION FOR BLINd [ðŸ”—GitHub Link](https://github.com/3003sakshi/main-project)

**Description:** Gesture Recognition for Blind Assistance ðŸ‘‹ðŸ¤–
The Gesture Recognition for Blind Assistance project is designed to empower individuals with visual impairments by enabling them to communicate through hand gestures. This system uses computer vision and machine learning technologies, specifically OpenCV, MediaPipe, and pyttsx3, to recognize a wide range of hand gestures and convert them into speech.

The core idea is to help blind users express their needs, such as emergency assistance, location information, and requests for help, through simple hand gestures. It also supports recognizing basic American Sign Language (ASL) alphabets, allowing users to convey more complex messages.

Key Features:

Real-time Gesture Recognition: The system captures and processes hand gestures in real-time, providing immediate feedback.

Text-to-Speech (TTS) Output: Recognized gestures are translated into spoken messages, which are announced aloud, making communication accessible for blind individuals.

Predefined Blind Assistance Gestures: The system includes specific gestures that represent urgent requests like emergency help, requests for guidance, and even inquiries about location.

ASL Alphabet Recognition: The system can detect and identify individual ASL letters, allowing users to communicate more complex messages through sign language.

Interactive UI: The program includes an intuitive user interface that lets the user start or stop gesture recognition with a single click, making it easy to operate.

Customization and Scalability: Users can easily add or modify gestures to fit their specific needs.

This project also explores wearable device integration such as wristbands, which would allow users to interact with the system hands-free, further improving mobility and accessibility. Haptic feedback and IoT capabilities could be integrated to enhance the user experience by providing real-time alerts and remote gesture analysis.

Target Audience: This project is aimed at people with visual impairments or those who use ASL for communication, offering them a more intuitive and efficient way to interact with their environment and get assistance.

Future Potential: With further development, the system could integrate more advanced features like multilingual speech synthesis, deep learning-based gesture recognition, and even a mobile app for greater accessibility.
